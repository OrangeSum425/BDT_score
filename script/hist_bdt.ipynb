{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot as u\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from df_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = \"run3\"\n",
    "dm_type = \"fermion\"\n",
    "mass = \"0.05\"\n",
    "target_pot = 1.\n",
    "signal_pot = {}\n",
    "\n",
    "bkg_upper_limit = 1.14 \n",
    "\n",
    "\n",
    "if(dm_type == \"fermion\"):\n",
    "    signal_pot = { \"0.01\":4.49230189e+20, \"0.02\":3.24986846e+21, \"0.03\":1.44413783e+22, \n",
    "                  \"0.04\":5.51306150e+22, \"0.05\":1.74805153e+23, \"0.06\":5.79056950e+23,\n",
    "                  \"0.07\":1.48783150e+24, \"0.08\":4.41322940e+24, \n",
    "                  \"0.09\":9.92424735e+24, \"0.10\":2.27414738e+25}\n",
    "\n",
    "else: \n",
    "    signal_pot = { \"0.01\":8.70545727e+21, \"0.02\": 9.48797710e+22, \"0.03\":4.86277630e+23, \n",
    "                  \"0.04\":1.94231827e+24, \"0.05\":8.19564834e+24, \"0.06\":2.06542023e+25,\n",
    "                  \"0.07\":5.83217654e+25, \"0.08\":1.54999742e+26, \n",
    "                  \"0.09\":2.94329651e+26, \"0.10\":5.04481005e+26}\n",
    "\n",
    "\n",
    "scalings_run1 = { \"nu\":1./2.34e21, \"dirt\":0.75/1.6e21, \"beamoff\": 1.56*0.98}\n",
    "scalings_run3 = { \"nu\":1./1.993661e21, \"dirt\":0.35/1.020e21, \"beamoff\": 2.909}\n",
    "\n",
    "scalings = {}\n",
    "\n",
    "if(run == \"run1\"):\n",
    "    target_pot = 2.0e20\n",
    "    scalings = scalings_run1\n",
    "    pot_label = r'                    $2\\times10^{20}$ POT'\n",
    "else:\n",
    "    target_pot = 5.0e20\n",
    "    scalings = scalings_run3\n",
    "    pot_label = r'                    $5\\times10^{20}$ POT'\n",
    "\n",
    "signal_scaling = target_pot/signal_pot[mass]\n",
    "nu_scaling = target_pot*scalings[\"nu\"]\n",
    "dirt_scaling = target_pot*scalings[\"dirt\"]\n",
    "offbeam_scaling = scalings[\"beamoff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ppfx_cv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mf:\\Program Files (x86)\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mf:\\Program Files (x86)\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mf:\\Program Files (x86)\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ppfx_cv'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m df_offbeam \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(base_dir \u001b[39m+\u001b[39m run \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_offbeam_score.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m MC_weight_branch(df_nu)\n\u001b[1;32m---> 11\u001b[0m MC_weight_branch(df_dirt)\n",
      "File \u001b[1;32me:\\BDT_score\\script\\df_utils.py:47\u001b[0m, in \u001b[0;36mMC_weight_branch\u001b[1;34m(df_MC)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mMC_weight_branch\u001b[39m(df_MC): \n\u001b[0;32m     46\u001b[0m     \u001b[39m#Writes a new branch called \"weight\" including, ppfx, weightSplineTimesTune AND if pi0 are present, scales by pi0 factor\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     df_MC[\u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_MC[\u001b[39m\"\u001b[39;49m\u001b[39mppfx_cv\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m*\u001b[39mdf_MC[\u001b[39m\"\u001b[39m\u001b[39mweightSplineTimesTune\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mf:\\Program Files (x86)\\lib\\site-packages\\pandas\\core\\frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mf:\\Program Files (x86)\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ppfx_cv'"
     ]
    }
   ],
   "source": [
    "base_dir = \"E:/data/\" + run + \"_samples/\" \n",
    "plots_dir = \"E:/result/bdt/\"\n",
    "\n",
    "df_signal = pd.read_csv(base_dir + \"df_trident\" + \"_\" + mass + \"_score_test.csv\")\n",
    "df_nu = pd.read_csv(base_dir + run + \"_CV_score.csv\")\n",
    "df_dirt = pd.read_csv(base_dir + run + \"_dirt_score.csv\")\n",
    "df_offbeam = pd.read_csv(base_dir + run + \"_offbeam_score.csv\")\n",
    "\n",
    "\n",
    "MC_weight_branch(df_nu)\n",
    "MC_weight_branch(df_dirt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_transform(score):\n",
    "    return np.log(score/(1-score))\n",
    "\n",
    "def filter_df(df):\n",
    "    df = df[df['bdt_score'] >= 0.5]\n",
    "    return df\n",
    "\n",
    "\n",
    "def GetStatsUncert(df_a, variable,  weight_array, pot_weight):\n",
    "    (counts_df, bins_df) = np.histogram(df_a[variable], bins = binning, weights=np.square(weight_array*pot_weight))\n",
    "    counts_df[counts_df == 0.] = bkg_upper_limit*np.square(pot_weight)\n",
    "    return counts_df \n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signal = filter_df(df_signal)\n",
    "df_nu = filter_df(df_nu)\n",
    "df_dirt = filter_df(df_dirt)\n",
    "df_offbeam = filter_df(df_offbeam)\n",
    "\n",
    "\n",
    "df_signal['bdt_score'] = logit_transform(df_signal['bdt_score'])\n",
    "df_nu['bdt_score'] = logit_transform(df_nu['bdt_score'])\n",
    "df_dirt['bdt_score'] = logit_transform(df_dirt['bdt_score'])\n",
    "df_offbeam['bdt_score'] = logit_transform(df_offbeam['bdt_score'])\n",
    "\n",
    "\n",
    "print(\"Maximum of signal score:\", np.max(df_signal['bdt_score']))\n",
    "\n",
    "n_bins = 9\n",
    "binning = np.linspace(0., np.max(df_signal['bdt_score']) ,n_bins+1)\n",
    "binning = np.delete(binning, [len(binning) - 3, len(binning) - 2])\n",
    "print(\"Binning: \", binning.tolist())\n",
    "variable = 'bdt_score'\n",
    "bdt_range = (0., binning[-1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(counts_signal, bins_signal) = np.histogram(df_signal[variable], bins = binning)\n",
    "(counts_nu, bins_nu) = np.histogram(df_nu[variable], bins = binning, weights = df_nu['weight'])\n",
    "(counts_dirt, bins_dirt) = np.histogram(df_dirt[variable], bins = binning, weights = df_dirt['weight'])\n",
    "(counts_offbeam, bins_offbeam) = np.histogram(df_offbeam[variable], bins = binning)\n",
    "\n",
    "print(counts_signal*signal_scaling)\n",
    "\n",
    "\n",
    "#(counts_signal, bins_signal) = np.histogram(logit_transform(df_signal['bdt_score']), bins = n_bins)\n",
    "#(counts_nu, bins_nu) = np.histogram(logit_transform(df_nu['bdt_score']), bins = n_bins)\n",
    "#(counts_dirt, bins_dirt) = np.histogram(logit_transform(df_dirt['bdt_score']), bins = n_bins)\n",
    "#(counts_offbeam, bins_offbeam) = np.histogram(logit_transform(df_offbeam['bdt_score']), bins = n_bins)\n",
    "\n",
    "# This adds 68% upper limit on top of those bins with zero events \n",
    "counts_dirt[counts_dirt == 0.] = bkg_upper_limit\n",
    "counts_offbeam[counts_offbeam == 0.] = bkg_upper_limit\n",
    "\n",
    "\n",
    "print(\"Showing results for: \" + run)\n",
    "print(\"Number of dark tridents M_A=\"+str(mass)+\" :\" + str(np.sum(counts_signal)*signal_scaling))\n",
    "print(\"Number of neutrinos: \" + str(np.sum(counts_nu)*nu_scaling))\n",
    "print(\"Number of dirt: \" + str(np.sum(counts_dirt)*dirt_scaling))\n",
    "print(\"Number of beam-off: \" + str(np.sum(counts_offbeam)*offbeam_scaling))\n",
    "\n",
    "# Set plot specs with patches!!!\n",
    "\n",
    "dt_legend = r'DT ({:.2f})'.format(np.sum(counts_signal)*signal_scaling)\n",
    "nu_legend = r'in cryo $\\nu$ ({:.2f})'.format(np.sum(counts_nu)*nu_scaling)\n",
    "dirt_legend = r'out of cryo $\\nu$ ({:.2f})'.format(np.sum(counts_dirt)*dirt_scaling)\n",
    "beamoff_legend = r'beam-off ({:.2f})'.format(np.sum(counts_offbeam)*offbeam_scaling)\n",
    "\n",
    "stacked_colors = [\"darkviolet\",\"navy\",\"deepskyblue\"]\n",
    "stacked_legend = [nu_legend, dirt_legend, beamoff_legend]\n",
    "stacked_bins = [bins_nu[:-1], bins_dirt[:-1], bins_offbeam[:-1]]\n",
    "stacked_list = [counts_nu*nu_scaling, counts_dirt*dirt_scaling, counts_offbeam*offbeam_scaling ]\n",
    "plt.figure(figsize=(10,7),dpi=300)\n",
    "plt.hist(stacked_bins, bins = bins_nu, weights = stacked_list, histtype='stepfilled',stacked=True, color = stacked_colors, edgecolor=\"darkred\", label = stacked_legend)\n",
    "plt.hist(bins_signal[:-1], bins = bins_signal,weights=counts_signal*signal_scaling*10, histtype='step',label=dt_legend ,fill=False, edgecolor='gold', linewidth='2.')\n",
    "plt.legend(loc=\"upper center\",fontsize=10)\n",
    "plt.title(r'MicroBooNE NuMI data' + ' ' + run + ', ' + dm_type + ' DM' + pot_label ,fontsize=15)\n",
    "plt.xlim(0.,5.)\n",
    "plt.xticks(size=10)\n",
    "plt.yticks(size=10)\n",
    "plt.xlabel(r'BDT score',fontsize=15,labelpad=7)\n",
    "plt.ylabel(\"Events\",fontsize=15, labelpad=7)\n",
    "plt.xlim(bdt_range)\n",
    "plt.savefig(plots_dir + dm_type + \"_BDT_logits_\" + run + \"_dist.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46cdffcc58d91018f14844fc386a0037dbb58705246bdb6354ec5bc22c6f5a53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
